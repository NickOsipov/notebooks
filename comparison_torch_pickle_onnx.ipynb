{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVyVuEVgw0meKqbiKZiuC2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NickOsipov/notebooks/blob/main/comparison_torch_pickle_onnx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Пожалуйста, делайте копию на свой Google Drive!"
      ],
      "metadata": {
        "id": "CUMOOnceRmqD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Сравнение методов сериализации"
      ],
      "metadata": {
        "id": "l1ZEIiVI2M9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx onnxruntime"
      ],
      "metadata": {
        "id": "D4J5VDIak_Mq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29e7c0a0-c84d-4b73-8bec-6b4115516b2f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.14.1)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx, humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.18.0 onnxruntime-1.22.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "import onnx\n",
        "import onnxruntime\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Subset\n",
        "import random\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "PIDDM5RqmEt5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ComplexCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ComplexCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "9ITqGleomJUf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка и подготовка данных (оставлено без изменений)\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
        ")\n",
        "train_set = torchvision.datasets.MNIST(\n",
        "    root='./data', train=True, download=True, transform=transform\n",
        ")\n",
        "\n",
        "num_samples = 1000\n",
        "indices = random.sample(range(len(train_set)), num_samples)\n",
        "limited_set = Subset(train_set, indices)\n",
        "train_loader = torch.utils.data.DataLoader(limited_set, batch_size=4, shuffle=True)"
      ],
      "metadata": {
        "id": "V23E484hmLfJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49c98852-79bd-41ed-c9f2-d2b8a2a43fa4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 35.1MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.38MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 9.95MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 10.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение модели\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ComplexCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "n_epoch = 2\n",
        "sep = \"-\" * 60\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "    print(sep)\n",
        "    print(f\"Epoch: {epoch}\")\n",
        "\n",
        "    losses = []\n",
        "\n",
        "    for data in tqdm(train_loader):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss)\n",
        "\n",
        "    epoch_loss = torch.mean(torch.tensor(losses))\n",
        "    print(f\"\\nLoss: {epoch_loss}\")\n",
        "else:\n",
        "    print(sep)\n",
        "    print(\"Обучение завершено\")"
      ],
      "metadata": {
        "id": "x1M0lRAYmVT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dfc19b7-479b-44b3-86f6-d2f28d0fcb40"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------\n",
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 250/250 [00:21<00:00, 11.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loss: 2.307921886444092\n",
            "------------------------------------------------------------\n",
            "Epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 250/250 [00:16<00:00, 14.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loss: 2.3026809692382812\n",
            "------------------------------------------------------------\n",
            "Обучение завершено\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Сохранение модели различными способами\n",
        "\n",
        "# 1. PyTorch\n",
        "torch.save(model.state_dict(), \"cnn_pytorch.pth\")\n",
        "print(\"Модель сохранена в формате PyTorch\")\n",
        "\n",
        "# 2. Pickle\n",
        "with open(\"cnn_pickle.pkl\", \"wb\") as f:\n",
        "    pickle.dump(model, f)\n",
        "print(\"Модель сохранена в формате Pickle\")\n",
        "\n",
        "# 3. ONNX\n",
        "dummy_input = torch.randn(1, 1, 28, 28).to(device)\n",
        "torch.onnx.export(model, dummy_input, \"cnn.onnx\", verbose=True)\n",
        "print(\"Модель сохранена в формате ONNX\")"
      ],
      "metadata": {
        "id": "CZA5u_U4mdHR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c836df30-4810-4ba7-e04d-9e558920bed2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модель сохранена в формате PyTorch\n",
            "Модель сохранена в формате Pickle\n",
            "Модель сохранена в формате ONNX\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка моделей\n",
        "\n",
        "def print_load_time(start_time, model):\n",
        "    print(\"--------------------------------------------------------\")\n",
        "    print(f\"Модель: {model}\")\n",
        "    print(f\"Время десереализации: {time.time() - start_time:.6f} секунд\")\n",
        "\n",
        "# 1. PyTorch\n",
        "start_time = time.time()\n",
        "pytorch_model = ComplexCNN().to(device)\n",
        "pytorch_model.load_state_dict(torch.load(\"cnn_pytorch.pth\"))\n",
        "pytorch_model.eval()\n",
        "print_load_time(start_time, \"PyTorch\")\n",
        "\n",
        "# 2. Pickle\n",
        "start_time = time.time()\n",
        "with open(\"cnn_pickle.pkl\", \"rb\") as f:\n",
        "    pickle_model = pickle.load(f)\n",
        "pickle_model.eval()\n",
        "print_load_time(start_time, \"Pickle\")\n",
        "\n",
        "# 3. ONNX\n",
        "start_time = time.time()\n",
        "onnx_model = onnx.load(\"cnn.onnx\")\n",
        "onnx.checker.check_model(onnx_model)\n",
        "ort_session = onnxruntime.InferenceSession(\"cnn.onnx\")\n",
        "print_load_time(start_time, \"ONNX\")\n",
        "\n",
        "print(\"\\nВсе модели загружены\")"
      ],
      "metadata": {
        "id": "oTPJnzfXo7Wq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5b969ac-c2f7-48f4-c76f-35153ab82287"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------\n",
            "Модель: PyTorch\n",
            "Время десереализации: 0.033961 секунд\n",
            "--------------------------------------------------------\n",
            "Модель: Pickle\n",
            "Время десереализации: 0.011964 секунд\n",
            "--------------------------------------------------------\n",
            "Модель: ONNX\n",
            "Время десереализации: 0.038799 секунд\n",
            "\n",
            "Все модели загружены\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def measure_inference_time(model_func, input_tensor, num_iterations=1000):\n",
        "    times = []\n",
        "    for _ in range(num_iterations):\n",
        "        start_time = time.time()\n",
        "        _ = model_func(input_tensor)\n",
        "        end_time = time.time()\n",
        "        times.append(end_time - start_time)\n",
        "    return times\n",
        "\n",
        "def bootstrap_analysis(times, num_bootstrap=1000, confidence=0.95):\n",
        "    means = []\n",
        "    for _ in range(num_bootstrap):\n",
        "        sample = np.random.choice(times, size=len(times), replace=True)\n",
        "        means.append(np.mean(sample))\n",
        "\n",
        "    mean = np.mean(means)\n",
        "    ci_lower, ci_upper = np.percentile(means, [(1-confidence)/2 * 100, (1+confidence)/2 * 100])\n",
        "    return mean, ci_lower, ci_upper"
      ],
      "metadata": {
        "id": "rYzGWOSjxcw0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Подготовка входных данных\n",
        "input_tensor = torch.randn(1, 1, 28, 28).to(device)\n",
        "onnx_input = {ort_session.get_inputs()[0].name: input_tensor.cpu().numpy()}\n",
        "\n",
        "# Измерение времени инференса\n",
        "original_times = measure_inference_time(model, input_tensor)\n",
        "pytorch_times = measure_inference_time(pytorch_model, input_tensor)\n",
        "pickle_times = measure_inference_time(pickle_model, input_tensor)\n",
        "onnx_times = measure_inference_time(lambda x: ort_session.run(None, onnx_input), onnx_input)\n",
        "\n",
        "models = ['Original', 'PyTorch', 'Pickle', 'ONNX']\n",
        "times_list = [original_times, pytorch_times, pickle_times, onnx_times]"
      ],
      "metadata": {
        "id": "PE0FrcD_yF2E"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_name_length = max(len(name) for name in models)\n",
        "for model_name, times_ in zip(models, times_list):\n",
        "    print(f\"Среднее время инференса {model_name:<{max_name_length}}: {np.mean(times_):.6f} секунд\")"
      ],
      "metadata": {
        "id": "AW4p_ah1yI1L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6070083d-5363-4415-8aae-32fcda43a52d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Среднее время инференса Original: 0.006360 секунд\n",
            "Среднее время инференса PyTorch : 0.006606 секунд\n",
            "Среднее время инференса Pickle  : 0.006873 секунд\n",
            "Среднее время инференса ONNX    : 0.003747 секунд\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Выполнение bootstrap-анализа\n",
        "sep_1 = \"=\" * 60\n",
        "sep_2 = \"-\" * 60\n",
        "\n",
        "print(sep_1)\n",
        "print(\"Результаты bootstrap-анализа (95% доверительный интервал):\")\n",
        "print(sep_2)\n",
        "for model_name, times_ in zip(models, times_list):\n",
        "    mean, ci_lower, ci_upper = bootstrap_analysis(times_)\n",
        "    print(f\"{model_name:<{max_name_length}}: {mean:.6f} секунд ({ci_lower:.6f} - {ci_upper:.6f})\")\n",
        "\n",
        "print()\n",
        "print(sep_1)\n",
        "print(\"Сравнение производительности:\")\n",
        "print(sep_2)\n",
        "for model_name, times_ in zip(models[1:], times_list[1:]):\n",
        "    speedup = np.mean(original_times) / np.mean(times_)\n",
        "    print(f\"Ускорение {model_name:<{max_name_length}}: {speedup:.2f}x\")\n",
        "\n",
        "# Статистический тест (t-test) для сравнения с оригинальной моделью\n",
        "print()\n",
        "print(sep_1)\n",
        "print(\"Статистическая значимость (p-value):\")\n",
        "print(sep_2)\n",
        "for model_name, times_ in zip(models[1:], times_list[1:]):\n",
        "    t_stat, p_value = stats.ttest_ind(original_times, times_)\n",
        "    print(f\"{model_name:<{max_name_length}} vs Original: p-value = {p_value}\")"
      ],
      "metadata": {
        "id": "XW__gCmptm8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cad0cfb-de6d-4c6b-8eb8-292a6f7db595"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Результаты bootstrap-анализа (95% доверительный интервал):\n",
            "------------------------------------------------------------\n",
            "Original: 0.006360 секунд (0.006314 - 0.006411)\n",
            "PyTorch : 0.006608 секунд (0.006549 - 0.006671)\n",
            "Pickle  : 0.006884 секунд (0.006636 - 0.007149)\n",
            "ONNX    : 0.003746 секунд (0.003705 - 0.003791)\n",
            "\n",
            "============================================================\n",
            "Сравнение производительности:\n",
            "------------------------------------------------------------\n",
            "Ускорение PyTorch : 0.96x\n",
            "Ускорение Pickle  : 0.93x\n",
            "Ускорение ONNX    : 1.70x\n",
            "\n",
            "============================================================\n",
            "Статистическая значимость (p-value):\n",
            "------------------------------------------------------------\n",
            "PyTorch  vs Original: p-value = 1.9029182946460803e-09\n",
            "Pickle   vs Original: p-value = 0.00010891357510157145\n",
            "ONNX     vs Original: p-value = 0.0\n"
          ]
        }
      ]
    }
  ]
}